{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku6xX6N7dVKN",
        "outputId": "95d6d240-51a9-44ab-ff1e-bd0f7debba87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.11.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.43.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install h5py\n",
        "! pip install typing-extensions\n",
        "! pip install wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXX7MX4Cce6t",
        "outputId": "6fbe3ed4-9638-4f6e-e837-6ec60aae275c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytorchvideo in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (0.1.5.post20221221)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (12.0.0)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (0.1.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (1.25.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (4.66.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo) (4.11.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo) (2.8.2)\n",
            "Collecting torchvision==0.14.1\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (4.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.31.0)\n",
            "Collecting torch==1.13.1 (from torchvision==0.14.1)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (9.4.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->torchvision==0.14.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2024.2.2)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchvision-0.14.1\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets\n",
        "! pip install -q pytorchvideo transformers evaluate\n",
        "! pip install pytorchvideo\n",
        "! pip install torchvision==0.14.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqI7_Ynhh3E0"
      },
      "source": [
        "1. Download Data, model and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0B1a87ngRG9"
      },
      "source": [
        "Cần thay đổi chỗ này thành download video của BTC (hiện tại đang là video test của nhóm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dHAoUOuVicd",
        "outputId": "030493fd-e0aa-4c99-8921-27b51ac36704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1nnCAtnAdSBAyw22JJVqArZHApBfW5vvo\n",
            "From (redirected): https://drive.google.com/uc?id=1nnCAtnAdSBAyw22JJVqArZHApBfW5vvo&confirm=t&uuid=06799389-48ea-41aa-9bf1-f7839ddefbdd\n",
            "To: /content/round2_test.zip\n",
            "100% 106M/106M [00:02<00:00, 41.2MB/s] \n",
            "Archive:  round2_test.zip\n",
            "   creating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/\n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/barbell biceps curl_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/bench press_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/bench press_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/chest fly machine_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/chest fly machine_3.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/chest fly machine_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/deadlift_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/declince bench press_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/decline bench press_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/hammer curl_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/hammer curl_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/hip thrust_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/hip thrush_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/incline bench press_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/incline bench press_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/lat pulldown_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/lat pulldown_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/lateral raise_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/leg extension_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/leg extension_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/leg raises_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/plank_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/leg raises_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/pull up_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/pull up_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/push-up_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/romanian deadlift_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/romanian deadlift_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/russian twist_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/russian twist_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/sholder press_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/shoulder press_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/squat_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/squat_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/t bar row_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/t bat row_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/tricep dips_2.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/tricep dips_1.mp4  \n",
            "  inflating: content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại/tricep pushdown_1.mp4  \n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1nnCAtnAdSBAyw22JJVqArZHApBfW5vvo'\n",
        "!unzip 'round2_test.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COUge0AvhK6H"
      },
      "source": [
        "Download model YoloV9 to preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXzr-zQIXgQe",
        "outputId": "ce10f6da-0a2c-4c49-e650-9d3ebdcc1fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1n3BpG0glA_jgBQLyi3jKE4tlBTi2l83B\n",
            "From (redirected): https://drive.google.com/uc?id=1n3BpG0glA_jgBQLyi3jKE4tlBTi2l83B&confirm=t&uuid=196f962e-68df-4f8e-9dc2-3ce40f3cf852\n",
            "To: /content/best_workout_4.pt\n",
            "100% 205M/205M [00:01<00:00, 115MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1n3BpG0glA_jgBQLyi3jKE4tlBTi2l83B'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9lEywa0JzuH"
      },
      "source": [
        "PREPROCESSING USING YOLOV9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azOva9OKXdNO",
        "outputId": "be86ba35-1d0c-4072-c36d-967b87b2c31c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 325 (delta 158), reused 155 (delta 155), pack-reused 109\u001b[K\n",
            "Receiving objects: 100% (325/325), 2.23 MiB | 6.09 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n",
            "/content/yolov9\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SkalskiP/yolov9.git\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4skaKpV4gtI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.general import non_max_suppression, scale_boxes\n",
        "from utils.torch_utils import select_device, smart_inference_mode\n",
        "import cv2  # Import OpenCV\n",
        "import numpy as np  # Ensure numpy is imported\n",
        "\n",
        "# Correctly placed letterbox function\n",
        "def letterbox(img, new_shape=(640, 640), color=(0, 0, 0)):\n",
        "    \"\"\"Resize image to a 32-pixel-multiple rectangle\"\"\"\n",
        "    shape = img.shape[:2]  # current shape [height, width]\n",
        "    if isinstance(new_shape, int):\n",
        "        new_shape = (new_shape, new_shape)\n",
        "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # width, height deltas\n",
        "    dw, dh = np.mod(dw, 64), np.mod(dh, 64)  # divide padding into 2 sides\n",
        "    dw /= 2\n",
        "    dh /= 2\n",
        "    if shape[::-1] != new_unpad:  # resize\n",
        "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "    top, bottom = round(dh - 0.1), round(dh + 0.1)\n",
        "    left, right = round(dw - 0.1), round(dw + 0.1)\n",
        "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
        "    return img\n",
        "\n",
        "@smart_inference_mode()\n",
        "def run_object_detection_video(weights='/content/best_workout_4.pt',\n",
        "                               source='./data_mae/train/lateral raise/lateral_raise_6.MOV',\n",
        "                               imgsz=(640, 640),\n",
        "                               conf_thres=0.5,\n",
        "                               iou_thres=0.5,\n",
        "                               device='0',\n",
        "                               classes=None,\n",
        "                               agnostic_nms=False):\n",
        "    # Setup\n",
        "    device = select_device(device)\n",
        "    model = DetectMultiBackend(weights, device=device, dnn=False)\n",
        "\n",
        "    # Video capture\n",
        "    vid_cap = cv2.VideoCapture(source)\n",
        "    assert vid_cap.isOpened(), f'Failed to open video {source}'\n",
        "\n",
        "    # List to store detections for each frame, including the frame number\n",
        "    frame_detections = []\n",
        "\n",
        "    frame_number = 0  # Initialize frame counter\n",
        "\n",
        "    total_frames = int(vid_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    original_fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
        "    duration = total_frames / original_fps\n",
        "    # Tính toán phần trăm và thời điểm bắt đầu, kết thúc để cắt\n",
        "    if duration > 60:\n",
        "        start_percent = 0\n",
        "        end_percent = 100\n",
        "    elif duration > 10:\n",
        "        start_percent = 0\n",
        "        end_percent = 100\n",
        "    else:\n",
        "        start_percent = 0\n",
        "        end_percent = 100\n",
        "\n",
        "    start_frame = int((start_percent / 100) * total_frames)\n",
        "    end_frame = int((end_percent / 100) * total_frames)\n",
        "    current_frame = 0\n",
        "    # Process each frame\n",
        "    while True:\n",
        "        ret, frame = vid_cap.read()\n",
        "        current_frame+=1\n",
        "        if not ret:\n",
        "            break\n",
        "        if start_frame <= current_frame <= end_frame:\n",
        "            # Convert BGR (OpenCV format) to RGB\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Resize and pad frame to model input size\n",
        "            img = letterbox(frame, new_shape=imgsz)\n",
        "            img = img.transpose((2, 0, 1))  # HWC to CHW\n",
        "            img = np.ascontiguousarray(img)\n",
        "\n",
        "            img = torch.from_numpy(img).to(device).float() / 255.0\n",
        "            img = img[None]  # add batch dimension\n",
        "\n",
        "            pred = model(img, augment=False, visualize=False)\n",
        "            pred = non_max_suppression(pred, conf_thres, iou_thres, classes=classes, agnostic=agnostic_nms)\n",
        "\n",
        "            detections = []\n",
        "            for i, det in enumerate(pred):  # detections per frame\n",
        "                if len(det):\n",
        "                    det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], frame.shape).round()\n",
        "\n",
        "                    for *xyxy, conf, cls in reversed(det):\n",
        "                        bbox = tuple(c.item() for c in xyxy)  # Convert bbox coordinates to tuple of floats\n",
        "                        # Now including frame_number in the detection information\n",
        "                        detections.append((cls.item(), conf.item(), bbox, current_frame))\n",
        "\n",
        "            if detections:  # If there are detections in the current frame\n",
        "                frame_detections.append(detections)\n",
        "\n",
        "    vid_cap.release()\n",
        "    return frame_detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKzLiLVjhaZn"
      },
      "source": [
        "Function resize video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBynozpB4oyL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def crop_and_resize_frames(input_video_path, output_video_path, predictions):\n",
        "    # Mở video gốc\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Lấy thông số frame rate và định dạng size của video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (224, 224))\n",
        "    frame_id = 1\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if 1:\n",
        "            largest_bbox = None\n",
        "            max_area = 0\n",
        "            for pred in predictions:\n",
        "                if pred[0][3] == frame_id:  # Kiểm tra frame_id của prediction\n",
        "                    _, _, bbox, _ = pred[0]\n",
        "                    x_min, y_min, x_max, y_max = bbox\n",
        "                    area = (x_max - x_min) * (y_max - y_min)\n",
        "                    if area > max_area:\n",
        "                        max_area = area\n",
        "                        largest_bbox = bbox\n",
        "            if largest_bbox is not None:\n",
        "                x_min, y_min, x_max, y_max = largest_bbox\n",
        "                cropped_frame = frame[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
        "            else:\n",
        "                # Nếu không có bbox, lấy toàn bộ khung hình\n",
        "                cropped_frame = frame\n",
        "\n",
        "            # Resize khung hình về 224x224\n",
        "            resized_frame = cv2.resize(cropped_frame, (224, 224))\n",
        "\n",
        "            # Viết frame đã chỉnh sửa vào file output\n",
        "            out.write(resized_frame)\n",
        "\n",
        "        frame_id += 1\n",
        "\n",
        "    # Giải phóng và đóng tất cả\n",
        "    cap.release()\n",
        "    out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMc5rYs8J4wL"
      },
      "source": [
        "Cần thay đổi ***data_dir*** là đường dẫn tới folder chứa các video test, ***output_dir*** nên giữ nguyên"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jRqR6GCX0qf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại\"\n",
        "output_dir = \"/content/ss4\"\n",
        "from pathlib import Path; Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "i = 0\n",
        "for video_file in os.listdir(data_dir):\n",
        "            input_video_path = os.path.join(data_dir, video_file)\n",
        "            filename_without_extension, _ = os.path.splitext(video_file)\n",
        "            output_video_path = f\"{output_dir}/{filename_without_extension}.mp4\"\n",
        "            print(filename_without_extension)\n",
        "            video_detections = run_object_detection_video(source=input_video_path)\n",
        "            crop_and_resize_frames(input_video_path, output_video_path, video_detections)\n",
        "            i+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omm2MyjmKLeR"
      },
      "source": [
        "Để inference thì các video phải nằm trong các thư mục (sai nhãn vẫn được nên chúng tôi random sao cho 1 thư mục có ít nhất 1 video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H4Lw0pdCZJl"
      },
      "outputs": [],
      "source": [
        "cd '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm-eOFZMLLJj"
      },
      "source": [
        "Tên các folder lúc train chúng tôi khác với BTC nên inference tôi cũng để tên folder như vậy, chúng tôi sẽ có bước chuẩn hóa trước khi ghi vào file csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_K0lyoNBW44"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Root directory name\n",
        "root_dir = \"Workout_Exercises\"\n",
        "\n",
        "# List of exercises - directory names\n",
        "exercises = [\n",
        "    \"barbell biceps curl\", \"bench press\", \"chest fly machine\", \"dbp\",\n",
        "    \"deadlift\", \"hammer curl\", \"hip thrust\", \"incline bench press\",\n",
        "    \"lat pulldown\", \"lateral raise\", \"leg extension\", \"leg raises\",\n",
        "    \"plank\", \"pull up\", \"push-up\", \"romanian deadlift\", \"russian twist\",\n",
        "    \"shoulder press\", \"squat\", \"t bar row\", \"tricep dips\", \"tricep pushdown\"\n",
        "]\n",
        "\n",
        "# Create root directory\n",
        "os.makedirs(root_dir, exist_ok=True)\n",
        "\n",
        "# Create each exercise directory within the root directory\n",
        "for exercise in exercises:\n",
        "    os.makedirs(os.path.join(root_dir, exercise), exist_ok=True)\n",
        "\n",
        "\"Directories created successfully.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tải video bonus phòng trường hợp video < class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtyfof_b1Cpc"
      },
      "outputs": [],
      "source": [
        "!gdown --id '12myvrR4hpmk_V-LCbGO_JRRaoL6hento'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMFNQc1tDAnK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Đường dẫn đến thư mục chứa video và thư mục đích\n",
        "source_dir = 'ss4'\n",
        "destination_dir = 'Workout_Exercises'\n",
        "\n",
        "# Lấy danh sách tất cả các video trong thư mục nguồn\n",
        "videos = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
        "\n",
        "# Lấy danh sách tất cả các thư mục con trong thư mục đích\n",
        "subdirectories = [d for d in os.listdir(destination_dir) if os.path.isdir(os.path.join(destination_dir, d))]\n",
        "\n",
        "for i, video in enumerate(videos):\n",
        "        destination_subdir = os.path.join(destination_dir, subdirectories[i % len(subdirectories)])\n",
        "        source_video_path = os.path.join(source_dir, video)\n",
        "        destination_video_path = os.path.join(destination_subdir, video)\n",
        "\n",
        "        # Di chuyển video\n",
        "        shutil.move(source_video_path, destination_video_path)\n",
        "        print(f'Moved \"{video}\" to \"{destination_subdir}\"')\n",
        "if len(videos) < len(subdirectories):\n",
        "      for sub in subdirectories:\n",
        "          full_sub_dir = f\"{destination_dir}/{sub}\"\n",
        "          if len(os.listdir(full_sub_dir)) == 0:\n",
        "              bonus_path = os.path.join(full_sub_dir, 'bonus.mp4')\n",
        "              shutil.copy('./bonus.mp4', bonus_path)\n",
        "              # Đổi tên file bonus sau khi sao chép\n",
        "              new_bonus_name = f\"bonus{sub}.mp4\"\n",
        "              new_bonus_path = os.path.join(full_sub_dir, new_bonus_name)\n",
        "              os.rename(bonus_path, new_bonus_path)\n",
        "              print(f'Renamed \"bonus.mp4\" to \"{new_bonus_name}\" in \"{full_sub_dir}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgQRcykKKes7"
      },
      "source": [
        "PROCESSING, nếu có yêu cầu cần restart (hoặc gặp thông báo lỗi) thì cứ restart và tiếp tục chạy tiếp (không cần chạy lại từ trên xuống)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GN1Sq9fDwmX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the root directory of your dataset\n",
        "dataset_root = '/content/Workout_Exercises'\n",
        "\n",
        "# Initialize an empty list to store the paths of all video files\n",
        "all_video_file_paths = []\n",
        "\n",
        "# Walk through the directory structure\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    for file in files:\n",
        "        # Check if the file is a video file by its extension (assuming .mp4)\n",
        "        if 1:\n",
        "            # Construct the full path of the file\n",
        "            full_path = os.path.join(root, file)\n",
        "            # Append the full path to the list\n",
        "            all_video_file_paths.append(full_path)\n",
        "print(all_video_file_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrzCY--5D6Wb"
      },
      "outputs": [],
      "source": [
        "class_labels = sorted({str(path).split(\"/\")[-2] for path in all_video_file_paths})\n",
        "label2id = {label: i for i, label in enumerate(class_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "print(f\"Unique classes: {list(label2id.keys())}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXVpmm3KD8eX"
      },
      "outputs": [],
      "source": [
        "import pytorchvideo.data\n",
        "\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    Normalize,\n",
        "    RandomShortSideScale,\n",
        "    RemoveKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        ")\n",
        "\n",
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Lambda,\n",
        "    RandomCrop,\n",
        "    RandomHorizontalFlip,\n",
        "    Resize,\n",
        "    RandomAffine,\n",
        "    ColorJitter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFHy5mY6KrRd"
      },
      "source": [
        "Load model được lưu ở Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSPryBb6D95a"
      },
      "outputs": [],
      "source": [
        "from transformers import VideoMAEImageProcessor, VideoMAEForVideoClassification\n",
        "\n",
        "model_ckpt = \"bluebird089/videomae-base-finetuned-kinetics-final-contest-baole1-0705\"\n",
        "image_processor = VideoMAEImageProcessor.from_pretrained(model_ckpt)\n",
        "model = VideoMAEForVideoClassification.from_pretrained(\n",
        "    model_ckpt,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH5cKv-OD-LG"
      },
      "outputs": [],
      "source": [
        "mean = image_processor.image_mean\n",
        "std = image_processor.image_std\n",
        "\n",
        "num_frames_to_sample = model.config.num_frames\n",
        "\n",
        "clip_duration = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-Jj9M3ID_Fq"
      },
      "outputs": [],
      "source": [
        "val_transform = Compose(\n",
        "    [\n",
        "        ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=Compose(\n",
        "                [\n",
        "                    UniformTemporalSubsample(num_frames_to_sample),\n",
        "                    Lambda(lambda x: x / 255.0),\n",
        "                    Normalize(mean, std),\n",
        "                    Resize((224,224)),\n",
        "                ]\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "import shutil\n",
        "checkpoints_path = '/content/Workout_Exercises/.ipynb_checkpoints'\n",
        "shutil.rmtree(checkpoints_path, ignore_errors=True)\n",
        "\n",
        "# Now, you can load your dataset as before\n",
        "test_dataset = pytorchvideo.data.Ucf101(\n",
        "    data_path='/content/Workout_Exercises',\n",
        "    clip_sampler=pytorchvideo.data.make_clip_sampler(\"uniform\", clip_duration),\n",
        "    decode_audio=False,\n",
        "    transform=val_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr_eUvNVEGz0"
      },
      "outputs": [],
      "source": [
        "print(test_dataset.num_videos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLNnSDG6EH5z"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "\n",
        "def unnormalize_img(img):\n",
        "    \"\"\"Un-normalizes the image pixels.\"\"\"\n",
        "    img = (img * std) + mean\n",
        "    img = (img * 255).astype(\"uint8\")\n",
        "    return img.clip(0, 255)\n",
        "\n",
        "def create_gif(video_tensor, filename=\"sample.gif\"):\n",
        "    \"\"\"Prepares a GIF from a video tensor.\n",
        "\n",
        "    The video tensor is expected to have the following shape:\n",
        "    (num_frames, num_channels, height, width).\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "    for video_frame in video_tensor:\n",
        "        frame_unnormalized = unnormalize_img(video_frame.permute(1, 2, 0).numpy())\n",
        "        frames.append(frame_unnormalized)\n",
        "    kargs = {\"duration\": 5}\n",
        "    imageio.mimsave(filename, frames, \"GIF\", **kargs)\n",
        "    return filename\n",
        "\n",
        "def display_gif(video_tensor, gif_name=\"sample.gif\"):\n",
        "    \"\"\"Prepares and displays a GIF from a video tensor.\"\"\"\n",
        "    video_tensor = video_tensor.permute(1, 0, 2, 3)\n",
        "    gif_filename = create_gif(video_tensor, gif_name)\n",
        "    return Image(filename=gif_filename)\n",
        "\n",
        "sample_video = next(iter(test_dataset))\n",
        "video_tensor = sample_video[\"video\"]\n",
        "display_gif(video_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rlLHc54EJhz"
      },
      "outputs": [],
      "source": [
        "sample_test_video = next(iter(test_dataset))\n",
        "video_tensor = sample_test_video[\"video\"]\n",
        "video_name = sample_test_video[\"video_name\"]\n",
        "video_label = id2label[sample_test_video[\"label\"]]\n",
        "display_gif(video_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwqTSVPbKzfd"
      },
      "source": [
        "Hậu xử lý, vì mô hình chúng tôi chia nhỏ video đầu vào thành các video có thời lượng ngắn nên cần biết sau khi tách nhỏ video nhỏ thuộc video lớn nào, predicted sẽ là số lần xuất hiện nhiều nhất"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apUnbZl5EL6H"
      },
      "outputs": [],
      "source": [
        "videos = []\n",
        "labels = []\n",
        "video_names = []\n",
        "for sample in test_dataset:\n",
        "    video_tensor = sample[\"video\"]\n",
        "    video_label = id2label[sample[\"label\"]]\n",
        "    video_name = sample[\"video_name\"]\n",
        "    videos.append(video_tensor)\n",
        "    labels.append(video_label)\n",
        "    video_names.append(video_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY5cZxMLEkoU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "def run_inference(model, video, label):\n",
        "    # (num_frames, num_channels, height, width)\n",
        "    perumuted_sample_test_video = video.permute(1, 0, 2, 3)\n",
        "    inputs = {\n",
        "        \"pixel_values\": perumuted_sample_test_video.unsqueeze(0),\n",
        "        # \"labels\": torch.tensor(\n",
        "        #     [label]\n",
        "        # ),  # this can be skipped if you don't have labels available.\n",
        "    }\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    model = model.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpON7gsJElM4"
      },
      "outputs": [],
      "source": [
        "predicted = []\n",
        "for index in range(len(videos)):\n",
        "  logits = run_inference(model, videos[index], labels[index])\n",
        "  predicted_class_idx = logits.argmax(-1).item()\n",
        "  predicted.append(model.config.id2label[predicted_class_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0a4t4paEn_a"
      },
      "outputs": [],
      "source": [
        "# Chuyển đổi list thành set để loại bỏ các phần tử trùng lặp\n",
        "S = set(video_names)\n",
        "\n",
        "print(S.__len__())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVU0Ip6tLEKy"
      },
      "source": [
        "Print thử kết quả, trước khi ghi vào file CSV chúng tôi cần chuẩn hóa tên 1 vài class để đảm bảo giống BTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM5GTR8fLoWA"
      },
      "outputs": [],
      "source": [
        "def changeName(label):\n",
        "  if label == 'dbp':\n",
        "    return 'decline bench press'\n",
        "  elif label == 'tricep pushdown':\n",
        "    return 'tricep Pushdown'\n",
        "  elif label == 'pull up':\n",
        "    return 'pull Up'\n",
        "  else:\n",
        "    return label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oehdQii-OG4N"
      },
      "source": [
        "Vui lòng sửa ***data_dir*** là thư mục chứa video test của BTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBn9EWtRMHHA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/content/drive/MyDrive/AI4LIFE2024-DATA/Test - Vòng loại\"\n",
        "\n",
        "def getVideoName(videoName):\n",
        "  base_name = videoName.split('.')[0]\n",
        "  for name in os.listdir(data_dir):\n",
        "        if name.split('.')[0] == base_name:\n",
        "              return name\n",
        "  return 'Error'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ2GiXoQuBhH"
      },
      "source": [
        "Lưu kết quả vào file result.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2X9rKVtEpXG"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import csv\n",
        "# List để lưu các id (vị trí) của phần tử từ S trong L\n",
        "indices = []\n",
        "\n",
        "filename = \"result.csv\"\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  csvwriter.writerow(['video', 'Dự đoán'])\n",
        "  for item in S:\n",
        "    if 'bonus' not in item:\n",
        "     try:\n",
        "        # print(item)\n",
        "        # Lặp qua từng phần tử của S và tìm id của nó trong L\n",
        "        # Lưu ý: Vòng lặp dưới đây sẽ tìm tất cả các vị trí của item trong L\n",
        "        indices = [i for i, x in enumerate(video_names) if x == item]\n",
        "        # print(indices)\n",
        "        values = [predicted[i] for i in indices]\n",
        "\n",
        "        # Sử dụng Counter để thống kê và tìm giá trị xuất hiện nhiều nhất\n",
        "        most_common_value, count = Counter(values).most_common(1)[0]\n",
        "\n",
        "        # print(f'Giá trị xuất hiện nhiều nhất là: {most_common_value} với {count}/{indices.__len__()} lần xuất hiện - label {item}')\n",
        "        value = changeName(most_common_value)\n",
        "        videoName = getVideoName(item)\n",
        "        csvwriter.writerow([videoName, value])\n",
        "        indices = []\n",
        "     except ValueError:\n",
        "        # Nếu phần tử không tồn tại trong L, bỏ qua\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEp4iAsCQ3Ph"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
